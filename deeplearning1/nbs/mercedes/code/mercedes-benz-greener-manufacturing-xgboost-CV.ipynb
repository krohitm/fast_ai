{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (4209, 378)\n",
      "Shape test: (4209, 377)\n"
     ]
    }
   ],
   "source": [
    "# read datasets\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in train.columns:\n",
    "    if train[c].dtype == 'object':\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA\n",
    "n_comp = 10\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "pca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=42)\n",
    "ica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1):\n",
    "    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
    "    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n",
    "y_train = train[\"y\"]\n",
    "y_mean = np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 397)\n"
     ]
    }
   ],
   "source": [
    "X, y = train.drop('y', axis=1).values, train.y.values\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(n_jobs = 1, base_score= y_mean, silent=True, objective='reg:linear')\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [500, 600, 700], \n",
    "    'learning_rate': [0.001, 0.005, 0.01],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'subsample': [0.90, 0.95, 0.1]}\n",
    "\n",
    "clf = GridSearchCV(model, xgb_params, cv = 5, verbose=1, n_jobs = -1)\n",
    "clf.fit(X, y)\n",
    "#grid = GridSearchCV(model, xgb_params, cv = 5, verbose=1, n_jobs = -1)\n",
    "#gridresults = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541374237439\n",
      "{'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343037 (0.045156) with: {'n_estimators': 500, 'subsample': 0.9, 'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.344804 (0.044274) with: {'n_estimators': 500, 'subsample': 0.95, 'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.340100 (0.040377) with: {'n_estimators': 500, 'subsample': 0.1, 'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.379539 (0.049579) with: {'n_estimators': 600, 'subsample': 0.9, 'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.381691 (0.048569) with: {'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.376959 (0.044740) with: {'n_estimators': 600, 'subsample': 0.1, 'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.409626 (0.052951) with: {'n_estimators': 700, 'subsample': 0.9, 'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.411964 (0.051840) with: {'n_estimators': 700, 'subsample': 0.95, 'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.407796 (0.048460) with: {'n_estimators': 700, 'subsample': 0.1, 'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.325724 (0.060135) with: {'n_estimators': 500, 'subsample': 0.9, 'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.324220 (0.062389) with: {'n_estimators': 500, 'subsample': 0.95, 'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.330698 (0.036533) with: {'n_estimators': 500, 'subsample': 0.1, 'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.358348 (0.069699) with: {'n_estimators': 600, 'subsample': 0.9, 'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.355324 (0.074132) with: {'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.367567 (0.040749) with: {'n_estimators': 600, 'subsample': 0.1, 'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.383105 (0.080298) with: {'n_estimators': 700, 'subsample': 0.9, 'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.379420 (0.085912) with: {'n_estimators': 700, 'subsample': 0.95, 'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.398472 (0.044033) with: {'n_estimators': 700, 'subsample': 0.1, 'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.320182 (0.058828) with: {'n_estimators': 500, 'subsample': 0.9, 'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.318834 (0.062363) with: {'n_estimators': 500, 'subsample': 0.95, 'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.322354 (0.035691) with: {'n_estimators': 500, 'subsample': 0.1, 'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.351918 (0.068063) with: {'n_estimators': 600, 'subsample': 0.9, 'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.349277 (0.074087) with: {'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.358956 (0.039389) with: {'n_estimators': 600, 'subsample': 0.1, 'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.376044 (0.078464) with: {'n_estimators': 700, 'subsample': 0.9, 'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.372193 (0.086458) with: {'n_estimators': 700, 'subsample': 0.95, 'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.389661 (0.042170) with: {'n_estimators': 700, 'subsample': 0.1, 'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.538182 (0.063642) with: {'n_estimators': 500, 'subsample': 0.9, 'learning_rate': 0.005, 'max_depth': 4}\n",
      "0.540116 (0.063285) with: {'n_estimators': 500, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 4}\n",
      "0.531054 (0.056510) with: {'n_estimators': 500, 'subsample': 0.1, 'learning_rate': 0.005, 'max_depth': 4}\n",
      "0.532922 (0.067212) with: {'n_estimators': 600, 'subsample': 0.9, 'learning_rate': 0.005, 'max_depth': 4}\n",
      "0.541374 (0.062475) with: {'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 4}\n",
      "0.530717 (0.055391) with: {'n_estimators': 600, 'subsample': 0.1, 'learning_rate': 0.005, 'max_depth': 4}\n",
      "0.529443 (0.069241) with: {'n_estimators': 700, 'subsample': 0.9, 'learning_rate': 0.005, 'max_depth': 4}\n",
      "0.540965 (0.062039) with: {'n_estimators': 700, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 4}\n",
      "0.528706 (0.054314) with: {'n_estimators': 700, 'subsample': 0.1, 'learning_rate': 0.005, 'max_depth': 4}\n",
      "0.480398 (0.130634) with: {'n_estimators': 500, 'subsample': 0.9, 'learning_rate': 0.005, 'max_depth': 6}\n",
      "0.465791 (0.151695) with: {'n_estimators': 500, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 6}\n",
      "0.521650 (0.051756) with: {'n_estimators': 500, 'subsample': 0.1, 'learning_rate': 0.005, 'max_depth': 6}\n",
      "0.472315 (0.125129) with: {'n_estimators': 600, 'subsample': 0.9, 'learning_rate': 0.005, 'max_depth': 6}\n",
      "0.456695 (0.149114) with: {'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 6}\n",
      "0.519557 (0.051188) with: {'n_estimators': 600, 'subsample': 0.1, 'learning_rate': 0.005, 'max_depth': 6}\n",
      "0.464084 (0.122346) with: {'n_estimators': 700, 'subsample': 0.9, 'learning_rate': 0.005, 'max_depth': 6}\n",
      "0.442773 (0.142185) with: {'n_estimators': 700, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 6}\n",
      "0.515107 (0.050367) with: {'n_estimators': 700, 'subsample': 0.1, 'learning_rate': 0.005, 'max_depth': 6}\n",
      "0.434111 (0.155913) with: {'n_estimators': 500, 'subsample': 0.9, 'learning_rate': 0.005, 'max_depth': 8}\n",
      "0.400881 (0.202015) with: {'n_estimators': 500, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 8}\n",
      "0.513280 (0.050089) with: {'n_estimators': 500, 'subsample': 0.1, 'learning_rate': 0.005, 'max_depth': 8}\n",
      "0.425834 (0.158444) with: {'n_estimators': 600, 'subsample': 0.9, 'learning_rate': 0.005, 'max_depth': 8}\n",
      "0.392030 (0.201851) with: {'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 8}\n",
      "0.509354 (0.049802) with: {'n_estimators': 600, 'subsample': 0.1, 'learning_rate': 0.005, 'max_depth': 8}\n",
      "0.413442 (0.161046) with: {'n_estimators': 700, 'subsample': 0.9, 'learning_rate': 0.005, 'max_depth': 8}\n",
      "0.371582 (0.203133) with: {'n_estimators': 700, 'subsample': 0.95, 'learning_rate': 0.005, 'max_depth': 8}\n",
      "0.503925 (0.049369) with: {'n_estimators': 700, 'subsample': 0.1, 'learning_rate': 0.005, 'max_depth': 8}\n",
      "0.513499 (0.060406) with: {'n_estimators': 500, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 4}\n",
      "0.516294 (0.056386) with: {'n_estimators': 500, 'subsample': 0.95, 'learning_rate': 0.01, 'max_depth': 4}\n",
      "0.501897 (0.058010) with: {'n_estimators': 500, 'subsample': 0.1, 'learning_rate': 0.01, 'max_depth': 4}\n",
      "0.498251 (0.054267) with: {'n_estimators': 600, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 4}\n",
      "0.498907 (0.052181) with: {'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.01, 'max_depth': 4}\n",
      "0.493405 (0.054342) with: {'n_estimators': 600, 'subsample': 0.1, 'learning_rate': 0.01, 'max_depth': 4}\n",
      "0.474575 (0.070006) with: {'n_estimators': 700, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 4}\n",
      "0.478438 (0.066532) with: {'n_estimators': 700, 'subsample': 0.95, 'learning_rate': 0.01, 'max_depth': 4}\n",
      "0.485182 (0.052896) with: {'n_estimators': 700, 'subsample': 0.1, 'learning_rate': 0.01, 'max_depth': 4}\n",
      "0.430564 (0.132263) with: {'n_estimators': 500, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 6}\n",
      "0.401907 (0.153618) with: {'n_estimators': 500, 'subsample': 0.95, 'learning_rate': 0.01, 'max_depth': 6}\n",
      "0.482939 (0.055460) with: {'n_estimators': 500, 'subsample': 0.1, 'learning_rate': 0.01, 'max_depth': 6}\n",
      "0.406716 (0.141793) with: {'n_estimators': 600, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 6}\n",
      "0.379586 (0.169644) with: {'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.01, 'max_depth': 6}\n",
      "0.474210 (0.056921) with: {'n_estimators': 600, 'subsample': 0.1, 'learning_rate': 0.01, 'max_depth': 6}\n",
      "0.387997 (0.155042) with: {'n_estimators': 700, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 6}\n",
      "0.363775 (0.183047) with: {'n_estimators': 700, 'subsample': 0.95, 'learning_rate': 0.01, 'max_depth': 6}\n",
      "0.466104 (0.061204) with: {'n_estimators': 700, 'subsample': 0.1, 'learning_rate': 0.01, 'max_depth': 6}\n",
      "0.386899 (0.170086) with: {'n_estimators': 500, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 8}\n",
      "0.347413 (0.204722) with: {'n_estimators': 500, 'subsample': 0.95, 'learning_rate': 0.01, 'max_depth': 8}\n",
      "0.469093 (0.062960) with: {'n_estimators': 500, 'subsample': 0.1, 'learning_rate': 0.01, 'max_depth': 8}\n",
      "0.366588 (0.179467) with: {'n_estimators': 600, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 8}\n",
      "0.330933 (0.216142) with: {'n_estimators': 600, 'subsample': 0.95, 'learning_rate': 0.01, 'max_depth': 8}\n",
      "0.453893 (0.074540) with: {'n_estimators': 600, 'subsample': 0.1, 'learning_rate': 0.01, 'max_depth': 8}\n",
      "0.354801 (0.186590) with: {'n_estimators': 700, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 8}\n",
      "0.317234 (0.227317) with: {'n_estimators': 700, 'subsample': 0.95, 'learning_rate': 0.01, 'max_depth': 8}\n",
      "0.441118 (0.084380) with: {'n_estimators': 700, 'subsample': 0.1, 'learning_rate': 0.01, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(learning_rate = 0.005, n_jobs = -1, base_score= y_mean, silent=True, objective='reg:linear')\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [600, 650, 700], \n",
    "    'max_depth': [4, 5, 6],\n",
    "    'subsample': [0.90, 0.95, 0.1]}\n",
    "\n",
    "grid = GridSearchCV(model, xgb_params, cv = 5, verbose=1, n_jobs = -1)\n",
    "gridresults = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541645700512\n",
      "{'n_estimators': 650, 'subsample': 0.95, 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "print(gridresults.best_score_)\n",
    "print(gridresults.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532922 (0.067212) with: {'n_estimators': 600, 'subsample': 0.9, 'max_depth': 4}\n",
      "0.541374 (0.062475) with: {'n_estimators': 600, 'subsample': 0.95, 'max_depth': 4}\n",
      "0.530717 (0.055391) with: {'n_estimators': 600, 'subsample': 0.1, 'max_depth': 4}\n",
      "0.530606 (0.068565) with: {'n_estimators': 650, 'subsample': 0.9, 'max_depth': 4}\n",
      "0.541646 (0.062057) with: {'n_estimators': 650, 'subsample': 0.95, 'max_depth': 4}\n",
      "0.530052 (0.055427) with: {'n_estimators': 650, 'subsample': 0.1, 'max_depth': 4}\n",
      "0.529443 (0.069241) with: {'n_estimators': 700, 'subsample': 0.9, 'max_depth': 4}\n",
      "0.540965 (0.062039) with: {'n_estimators': 700, 'subsample': 0.95, 'max_depth': 4}\n",
      "0.528706 (0.054314) with: {'n_estimators': 700, 'subsample': 0.1, 'max_depth': 4}\n",
      "0.503469 (0.097803) with: {'n_estimators': 600, 'subsample': 0.9, 'max_depth': 5}\n",
      "0.504126 (0.096995) with: {'n_estimators': 600, 'subsample': 0.95, 'max_depth': 5}\n",
      "0.525316 (0.052777) with: {'n_estimators': 600, 'subsample': 0.1, 'max_depth': 5}\n",
      "0.499759 (0.099575) with: {'n_estimators': 650, 'subsample': 0.9, 'max_depth': 5}\n",
      "0.500750 (0.092819) with: {'n_estimators': 650, 'subsample': 0.95, 'max_depth': 5}\n",
      "0.523979 (0.052386) with: {'n_estimators': 650, 'subsample': 0.1, 'max_depth': 5}\n",
      "0.498409 (0.098546) with: {'n_estimators': 700, 'subsample': 0.9, 'max_depth': 5}\n",
      "0.499487 (0.090192) with: {'n_estimators': 700, 'subsample': 0.95, 'max_depth': 5}\n",
      "0.522242 (0.051381) with: {'n_estimators': 700, 'subsample': 0.1, 'max_depth': 5}\n",
      "0.472315 (0.125129) with: {'n_estimators': 600, 'subsample': 0.9, 'max_depth': 6}\n",
      "0.456695 (0.149114) with: {'n_estimators': 600, 'subsample': 0.95, 'max_depth': 6}\n",
      "0.519557 (0.051188) with: {'n_estimators': 600, 'subsample': 0.1, 'max_depth': 6}\n",
      "0.467194 (0.124198) with: {'n_estimators': 650, 'subsample': 0.9, 'max_depth': 6}\n",
      "0.448559 (0.145183) with: {'n_estimators': 650, 'subsample': 0.95, 'max_depth': 6}\n",
      "0.517480 (0.050506) with: {'n_estimators': 650, 'subsample': 0.1, 'max_depth': 6}\n",
      "0.464084 (0.122346) with: {'n_estimators': 700, 'subsample': 0.9, 'max_depth': 6}\n",
      "0.442773 (0.142185) with: {'n_estimators': 700, 'subsample': 0.95, 'max_depth': 6}\n",
      "0.515107 (0.050367) with: {'n_estimators': 700, 'subsample': 0.1, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "means = gridresults.cv_results_['mean_test_score']\n",
    "stds = gridresults.cv_results_['std_test_score']\n",
    "params = gridresults.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(learning_rate = 0.005, n_jobs = -1, \n",
    "                         base_score= y_mean, silent=True, \n",
    "                         objective='reg:linear', max_depth = 4)\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [625, 650, 675], \n",
    "    'subsample': [0.90, 0.95, 0.1]}\n",
    "\n",
    "grid = GridSearchCV(model, xgb_params, cv = 5, verbose=1, n_jobs = -1)\n",
    "gridresults = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541645700512\n",
      "{'n_estimators': 650, 'subsample': 0.95}\n"
     ]
    }
   ],
   "source": [
    "print(gridresults.best_score_)\n",
    "print(gridresults.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532852 (0.067183) with: {'n_estimators': 625, 'subsample': 0.9}\n",
      "0.541411 (0.062440) with: {'n_estimators': 625, 'subsample': 0.95}\n",
      "0.531015 (0.055623) with: {'n_estimators': 625, 'subsample': 0.1}\n",
      "0.530606 (0.068565) with: {'n_estimators': 650, 'subsample': 0.9}\n",
      "0.541646 (0.062057) with: {'n_estimators': 650, 'subsample': 0.95}\n",
      "0.530052 (0.055427) with: {'n_estimators': 650, 'subsample': 0.1}\n",
      "0.530138 (0.069106) with: {'n_estimators': 675, 'subsample': 0.9}\n",
      "0.541254 (0.061785) with: {'n_estimators': 675, 'subsample': 0.95}\n",
      "0.529546 (0.054797) with: {'n_estimators': 675, 'subsample': 0.1}\n"
     ]
    }
   ],
   "source": [
    "means = gridresults.cv_results_['mean_test_score']\n",
    "stds = gridresults.cv_results_['std_test_score']\n",
    "params = gridresults.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=100.669318128, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.005, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=650,\n",
       "       n_jobs=-1, nthread=-1, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=0.95)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=650, learning_rate=0.005, \n",
    "                             max_depth=4, subsample=0.95, objective='reg:linear',\n",
    "                             base_score=y_mean, n_jobs=-1)\n",
    "xgb_model.fit(X, y, eval_metric='rmse', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63188961146\n"
     ]
    }
   ],
   "source": [
    "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print r2_score(y, xgb_model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_650_GCV0625.joblib.dat']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# save model to file\n",
    "joblib.dump(xgb_model, \"xgb_650_GCV0625.joblib.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 397)\n",
      "(4209, 397)\n"
     ]
    }
   ],
   "source": [
    "#xgb_model = joblib.load(\"xgb_650_GCV0625.joblib.dat\")\n",
    "x_test = np.array(test)\n",
    "#print x_test\n",
    "print x_test.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions and save results\n",
    "y_pred = xgb_model.predict(x_test)\n",
    "output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\n",
    "output.to_csv('xgb_650_GCV0625-pca-ica.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Trying with random search instead of grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "model = xgb.XGBRegressor(base_score= y_mean, silent=True, objective='reg:linear')\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [600, 625, 650, 675, 700], \n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'max_depth': [4, 5],\n",
    "    'subsample': [0.80, 0.85, 0.90, 0.95],\n",
    "    'gamma': [0, 0.05],\n",
    "    'colsample_bytree': [0.75, 1],\n",
    "    'colsample_bylevel': [0.75, 1]}\n",
    "\n",
    "clf = RandomizedSearchCV(model, xgb_params, cv = 5, verbose=1, \n",
    "                         n_iter=50, n_jobs = -1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538127937497\n",
      "{'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 600, 'subsample': 0.9, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.467630 (0.156224) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 650, 'subsample': 0.9, 'max_depth': 5, 'gamma': 0}\n",
      "0.486489 (0.126675) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 600, 'subsample': 0.8, 'max_depth': 5, 'gamma': 0}\n",
      "0.502740 (0.094620) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 625, 'subsample': 0.95, 'max_depth': 5, 'gamma': 0}\n",
      "0.492220 (0.055937) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 625, 'subsample': 0.9, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.483409 (0.069933) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 650, 'subsample': 0.8, 'max_depth': 4, 'gamma': 0}\n",
      "0.417274 (0.146922) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 600, 'subsample': 0.8, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.520226 (0.086696) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 650, 'subsample': 0.95, 'max_depth': 4, 'gamma': 0}\n",
      "0.482519 (0.131201) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 650, 'subsample': 0.8, 'max_depth': 5, 'gamma': 0}\n",
      "0.473479 (0.073964) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 675, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0}\n",
      "0.500781 (0.092843) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 650, 'subsample': 0.95, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.464025 (0.082736) with: {'colsample_bytree': 1, 'colsample_bylevel': 0.75, 'learning_rate': 0.01, 'n_estimators': 700, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.407411 (0.159106) with: {'colsample_bytree': 1, 'colsample_bylevel': 0.75, 'learning_rate': 0.01, 'n_estimators': 650, 'subsample': 0.9, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.532922 (0.067212) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 600, 'subsample': 0.9, 'max_depth': 4, 'gamma': 0}\n",
      "0.490667 (0.057541) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 675, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0}\n",
      "0.509372 (0.095236) with: {'colsample_bytree': 1, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 600, 'subsample': 0.8, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.494493 (0.109883) with: {'colsample_bytree': 1, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 600, 'subsample': 0.95, 'max_depth': 5, 'gamma': 0}\n",
      "0.405662 (0.152508) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 700, 'subsample': 0.8, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.482916 (0.062554) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 700, 'subsample': 0.95, 'max_depth': 4, 'gamma': 0}\n",
      "0.485282 (0.060527) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 700, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0}\n",
      "0.515702 (0.092015) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 600, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0}\n",
      "0.466775 (0.081589) with: {'colsample_bytree': 1, 'colsample_bylevel': 0.75, 'learning_rate': 0.01, 'n_estimators': 675, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.520204 (0.078532) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 625, 'subsample': 0.8, 'max_depth': 4, 'gamma': 0}\n",
      "0.489822 (0.111049) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 700, 'subsample': 0.9, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.530606 (0.068565) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 650, 'subsample': 0.9, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.450222 (0.115273) with: {'colsample_bytree': 1, 'colsample_bylevel': 0.75, 'learning_rate': 0.01, 'n_estimators': 700, 'subsample': 0.8, 'max_depth': 4, 'gamma': 0}\n",
      "0.488852 (0.114962) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 675, 'subsample': 0.85, 'max_depth': 5, 'gamma': 0}\n",
      "0.508095 (0.101579) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 700, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0}\n",
      "0.457784 (0.106641) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.01, 'n_estimators': 675, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0}\n",
      "0.472808 (0.105030) with: {'colsample_bytree': 1, 'colsample_bylevel': 0.75, 'learning_rate': 0.01, 'n_estimators': 600, 'subsample': 0.8, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.515702 (0.092015) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 600, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.407946 (0.195045) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.01, 'n_estimators': 625, 'subsample': 0.85, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.519597 (0.087191) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 675, 'subsample': 0.95, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.482697 (0.072478) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 600, 'subsample': 0.85, 'max_depth': 4, 'gamma': 0}\n",
      "0.492265 (0.110648) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 675, 'subsample': 0.9, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.434066 (0.113324) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 625, 'subsample': 0.9, 'max_depth': 5, 'gamma': 0}\n",
      "0.498409 (0.098546) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 700, 'subsample': 0.9, 'max_depth': 5, 'gamma': 0}\n",
      "0.451615 (0.182398) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 700, 'subsample': 0.85, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.438621 (0.110602) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 600, 'subsample': 0.9, 'max_depth': 5, 'gamma': 0}\n",
      "0.463789 (0.157629) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 700, 'subsample': 0.9, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.484209 (0.129041) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 625, 'subsample': 0.8, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.424913 (0.124309) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 700, 'subsample': 0.85, 'max_depth': 5, 'gamma': 0}\n",
      "0.471258 (0.145917) with: {'colsample_bytree': 1, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 650, 'subsample': 0.9, 'max_depth': 5, 'gamma': 0.05}\n",
      "0.491249 (0.110269) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 700, 'subsample': 0.85, 'max_depth': 5, 'gamma': 0}\n",
      "0.520592 (0.080628) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 600, 'subsample': 0.8, 'max_depth': 4, 'gamma': 0}\n",
      "0.483208 (0.069677) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 650, 'subsample': 0.8, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.533214 (0.066387) with: {'colsample_bytree': 1, 'colsample_bylevel': 0.75, 'learning_rate': 0.005, 'n_estimators': 700, 'subsample': 0.95, 'max_depth': 4, 'gamma': 0}\n",
      "0.517289 (0.081313) with: {'colsample_bytree': 1, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 675, 'subsample': 0.8, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.538128 (0.065607) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.005, 'n_estimators': 600, 'subsample': 0.9, 'max_depth': 4, 'gamma': 0.05}\n",
      "0.424609 (0.130707) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 675, 'subsample': 0.85, 'max_depth': 5, 'gamma': 0}\n",
      "0.425883 (0.121721) with: {'colsample_bytree': 0.75, 'colsample_bylevel': 1, 'learning_rate': 0.01, 'n_estimators': 675, 'subsample': 0.95, 'max_depth': 5, 'gamma': 0}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(colsample_bytree=0.75, colsample_bylevel=1, \n",
    "                             learning_rate=0.005, n_estimators=650, \n",
    "                             subsample=0.9, max_depth=4, \n",
    "                             gamma= 0.05, objective='reg:linear',\n",
    "                             base_score=y_mean, n_jobs=-1)\n",
    "\n",
    "xgb_model.fit(X, y, eval_metric='rmse', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6309514157\n"
     ]
    }
   ],
   "source": [
    "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print r2_score(y, xgb_model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.629841004819\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(colsample_bytree=0.75, colsample_bylevel=1, \n",
    "                             learning_rate=0.005, n_estimators=650, \n",
    "                             subsample=0.95, max_depth=4, \n",
    "                             gamma= 0.05, objective='reg:linear',\n",
    "                             base_score=y_mean, n_jobs=-1)\n",
    "\n",
    "xgb_model.fit(X, y, eval_metric='rmse', verbose=True)\n",
    "\n",
    "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print r2_score(y, xgb_model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
